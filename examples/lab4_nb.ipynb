{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccb2f919-e857-4e03-9fb1-52dc3cc18fb1",
   "metadata": {},
   "source": [
    "# Jupyter Notebook for the Module 4 Labs\n",
    "This notebook explores models based on an image classification model for the Fashion-MNIST dataset using tf.keras and trained using HPE Cray AI Development Environment. Extra code has been added for the purposes of this lab.\n",
    "\n",
    "Based on: https://www.tensorflow.org/tutorials/keras/classification.\n",
    "\n",
    "\n",
    "\n",
    "MIT License\n",
    "\n",
    "Copyright (c) 2017 Fran√ßois Chollet\n",
    "\n",
    " Permission is hereby granted, free of charge, to any person obtaining a\n",
    " copy of this software and associated documentation files (the \"Software\"),\n",
    " to deal in the Software without restriction, including without limitation\n",
    " the rights to use, copy, modify, merge, publish, distribute, sublicense,\n",
    " and/or sell copies of the Software, and to permit persons to whom the\n",
    " Software is furnished to do so, subject to the following conditions:\n",
    "\n",
    " The above copyright notice and this permission notice shall be included in\n",
    " all copies or substantial portions of the Software.\n",
    "\n",
    " THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    " IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    " FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n",
    " THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    " LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n",
    " FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n",
    " DEALINGS IN THE SOFTWARE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c7be78-e3b4-4ae6-b3ac-9ca1141c8b6b",
   "metadata": {},
   "source": [
    "## Module 4-Lab 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e4bfe3-25b9-4d3c-b3a4-864c67ec06b0",
   "metadata": {},
   "source": [
    "### Set up for validating trained models\n",
    "This code imports modules, loads validation data (fashion images), and prepares for displaying the results of passing validation images through the model. \n",
    "Run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274dc38f-a4da-4be1-bf55-8caedea3d11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tensorflow import keras\n",
    "import gzip\n",
    "import tempfile\n",
    "from tensorflow.python.keras.utils.data_utils import get_file\n",
    "print(\"TensorFlow version is \"+tf.__version__+\".\")\n",
    "\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "def load_validation_data():\n",
    "    \"\"\"Loads the Fashion-MNIST dataset.\n",
    "\n",
    "    Returns:\n",
    "        Tuple of Numpy arrays: `(x_test, y_test)`.\n",
    "\n",
    "    License:\n",
    "        The copyright for Fashion-MNIST is held by Zalando SE.\n",
    "        Fashion-MNIST is licensed under the [MIT license](\n",
    "        https://github.com/zalandoresearch/fashion-mnist/blob/master/LICENSE).\n",
    "\n",
    "    \"\"\"\n",
    "    base = \"/tmp/data/\"\n",
    "    files = [\n",
    "        \"t10k-labels-idx1-ubyte.gz\",\n",
    "        \"t10k-images-idx3-ubyte.gz\",\n",
    "    ]\n",
    "\n",
    "    paths = []\n",
    "    for fname in files:\n",
    "        paths.append(base + fname)\n",
    "\n",
    "    with gzip.open(paths[0], \"rb\") as lbpath:\n",
    "        y_test = np.frombuffer(lbpath.read(), np.uint8, offset=8)\n",
    "\n",
    "    with gzip.open(paths[1], \"rb\") as imgpath:\n",
    "        x_test = np.frombuffer(imgpath.read(), np.uint8, offset=16).reshape(len(y_test), 28, 28)\n",
    "\n",
    "    return x_test, y_test\n",
    "\n",
    "test_images, test_labels = load_validation_data()\n",
    "test_images = test_images / 255.0\n",
    "print(\"Validation data (fashion images) loaded.\")\n",
    "\n",
    "def plot_image(i, predictions_array, true_label, img):\n",
    "  true_label, img = true_label[i], img[i]\n",
    "  plt.grid(False)\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "\n",
    "  plt.imshow(img, cmap=plt.cm.binary)\n",
    "\n",
    "  predicted_label = np.argmax(predictions_array)\n",
    "  if predicted_label == true_label:\n",
    "    color = 'blue'\n",
    "  else:\n",
    "    color = 'red'\n",
    "\n",
    "  plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
    "                                100*np.max(predictions_array),\n",
    "                                class_names[true_label]),\n",
    "                                color=color)\n",
    "\n",
    "def plot_value_array(i, predictions_array, true_label):\n",
    "  true_label = true_label[i]\n",
    "  plt.grid(False)\n",
    "  plt.xticks(range(10))\n",
    "  plt.yticks([])\n",
    "  thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n",
    "  plt.ylim([0, 1])\n",
    "  predicted_label = np.argmax(predictions_array)\n",
    "\n",
    "  thisplot[predicted_label].set_color('red')\n",
    "  thisplot[true_label].set_color('blue')\n",
    "set = 0 \n",
    "num_rows = 5\n",
    "num_cols = 3\n",
    "num_images = num_rows*num_cols\n",
    "start_image = (set*num_images)\n",
    "end_image = (set*num_images)+num_images\n",
    "print(\"Display functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7146e929-f024-4e2f-b4a8-326640c48aab",
   "metadata": {},
   "source": [
    "### Load the trained model (trained on one GPU) \n",
    "In line 1 below, replace your_uuid with the checkpoint UUID that you collected during the lab. Make sure to leave the \"\" around the UUID.\n",
    "Then run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ca42e3-ef08-4b8f-a129-2a99d7acdfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "const_uuid = \"your_uuid\"\n",
    "const_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(10),\n",
    "])  \n",
    "const_model.load_weights(\"/tmp/determined-checkpoint/\"+const_uuid+\"/determined-keras-model-weights\").expect_partial()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057b7881-12c4-4484-b6df-833106202fd1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Run images through the trained model\n",
    "Run the cell below to run the images through the trained model and display the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25abf250-b1ce-48d6-a2aa-12bd1bf9e565",
   "metadata": {},
   "outputs": [],
   "source": [
    "const_probability_model = tf.keras.Sequential([const_model, \n",
    "                                         tf.keras.layers.Softmax()])\n",
    "const_predictions = const_probability_model.predict(test_images)\n",
    "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
    "for i in range(start_image, end_image):\n",
    "  index = i % num_images\n",
    "  plt.subplot(num_rows, 2*num_cols, 2*index+1)\n",
    "  plot_image(i, const_predictions[i], test_labels, test_images)\n",
    "  plt.subplot(num_rows, 2*num_cols, 2*index+2)\n",
    "  plot_value_array(i, const_predictions[i], test_labels)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f27fd5-fe88-4479-944b-cbd278742c65",
   "metadata": {},
   "source": [
    "### Stop\n",
    "You have completed Module 4-Lab 2.\n",
    "\n",
    "## Module 4-Lab 3\n",
    "\n",
    "### Load your model trained on multiple GPUs \n",
    "In line 1 below, replace your_uuid with the checkpoint UUID that you collected in this lab. Make sure to leave \"\" around the UUID.\n",
    "Then run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03c139e-bd04-4f47-b8eb-375f6e9b511d",
   "metadata": {},
   "outputs": [],
   "source": [
    "distributed_uuid = \"your_uuid\"\n",
    "distributed_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3,3), input_shape=(28,28,1), padding=\"same\", activation=\"relu\"),\n",
    "    tf.keras.layers.Conv2D(32, (3,3), padding=\"same\", activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPool2D(2,2),\n",
    "    tf.keras.layers.Dropout(0.45),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "    tf.keras.layers.Dropout(0.65),\n",
    "    tf.keras.layers.Dense(10),])  \n",
    "distributed_model.load_weights(\"/tmp/determined-checkpoint/\"+distributed_uuid+\"/determined-keras-model-weights\").expect_partial()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba0123f-4d4f-4f74-84c9-f21afe54f566",
   "metadata": {},
   "source": [
    "### Run images through the trained model\n",
    "Run the cell below to run the images through the trained model and display the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da35e381-7736-4246-8a7b-b632cb0b66ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_test_images = np.expand_dims(test_images, axis=-1)\n",
    "distributed_probability_model = tf.keras.Sequential([distributed_model, \n",
    "                                         tf.keras.layers.Softmax()])\n",
    "distributed_predictions = distributed_probability_model.predict(ch_test_images)\n",
    "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
    "for i in range(start_image, end_image):\n",
    "  index = i % num_images\n",
    "  plt.subplot(num_rows, 2*num_cols, 2*index+1)\n",
    "  plot_image(i, distributed_predictions[i], test_labels, test_images)\n",
    "  plt.subplot(num_rows, 2*num_cols, 2*index+2)\n",
    "  plot_value_array(i, distributed_predictions[i], test_labels)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb22e18d-4145-45b0-a5c5-0e9470a533bd",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Stop\n",
    "You have completed Module 4-Lab 3.\n",
    "\n",
    "## Module 4-Lab 4\n",
    "\n",
    "### Load the model created with Adaptive ASHA HPO \n",
    "- In line 1 below, change your_dense1 to the number that you recorded for the dense1 hyperparameter.\n",
    "- In line 2 below, change your_filters1 to the number that you recorded for the filters1 hyperparameter.\n",
    "- In line 3 below, change your_filters2 to the number that you recorded for the filters2 hyperparameter.\n",
    "- In line 4 below, replace your_uuid with the UUID you collected in this lab. Make sure to keep \"\" around the UUID. \n",
    "\n",
    "Then run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2005fa07-3c27-4b5f-9ee8-1289c2c80784",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense1 = your_dense1\n",
    "filters1 = your_filters1\n",
    "filters2 = your_filters2\n",
    "adaptive_uuid = \"your_uuid\"\n",
    "adaptive_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(filters1, (3,3), input_shape=(28,28,1), padding=\"same\", activation=\"relu\"),\n",
    "    tf.keras.layers.Conv2D(filters2, (3,3), padding=\"same\", activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPool2D(2,2),\n",
    "    tf.keras.layers.Dropout(0.45),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(dense1, activation=\"relu\"),\n",
    "    tf.keras.layers.Dropout(0.65),\n",
    "    tf.keras.layers.Dense(10),])  \n",
    "adaptive_model.load_weights(\"/tmp/determined-checkpoint/\"+adaptive_uuid+\"/determined-keras-model-weights\").expect_partial()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b310ef4c-5c48-409c-9ad4-e1fca37dcf67",
   "metadata": {},
   "source": [
    "## Run images through the trained model\n",
    "Run the cell below to run the images through the trained model and display the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfce888-3d0e-443d-b369-8e645f182b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "adaptive_probability_model = tf.keras.Sequential([adaptive_model, \n",
    "                                         tf.keras.layers.Softmax()])\n",
    "adaptive_predictions = adaptive_probability_model.predict(ch_test_images)\n",
    "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
    "for i in range(start_image, end_image):\n",
    "  index = i % num_images\n",
    "  plt.subplot(num_rows, 2*num_cols, 2*index+1)\n",
    "  plot_image(i, adaptive_predictions[i], test_labels, test_images)\n",
    "  plt.subplot(num_rows, 2*num_cols, 2*index+2)\n",
    "  plot_value_array(i, adaptive_predictions[i], test_labels)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f47bd3-264f-4418-9be6-ca4f00798411",
   "metadata": {
    "tags": []
   },
   "source": [
    "### You have completed Module 4-Lab 4\n",
    "\n",
    "## Optional: Additional validation\n",
    "If you want, you can compare the three models that you created in these labs on additional images:\n",
    "- Const Model = The model you trained on 5 epochs on 1 GPU with no HPO\n",
    "- Distributed Model = The model you trained on 12 epochs on 4 GPUs with no HPO\n",
    "- Adaptive Model = The best model obtained when you trained on up to 12 epochs with Adaptive ASHA\n",
    "\n",
    "Up to now you have been viewing images 1-15. \n",
    "Run the cell below to compare your three models on images 16-30. \n",
    "(If you want to compare on additional images, simply change the set number in line 1. Then run the cell again. You can keep changing the set number to see more images. The valid range is 0 to 665.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e2107b-785a-4d75-bb0d-2e7af722c9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "set = 1\n",
    "num_rows = 5\n",
    "num_cols = 3\n",
    "num_images = num_rows*num_cols\n",
    "start_image = (set*num_images)\n",
    "end_image = (set*num_images)+num_images\n",
    "\n",
    "print(\"\\033[1m\"+\"Const Model Results for Images \"+str(start_image)+\" to \"+str(end_image)+\"\\033[0m\")\n",
    "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
    "for i in range(start_image, end_image):\n",
    "  index = i % num_images\n",
    "  plt.subplot(num_rows, 2*num_cols, 2*index+1)\n",
    "  plot_image(i, const_predictions[i], test_labels, test_images)\n",
    "  plt.subplot(num_rows, 2*num_cols, 2*index+2)\n",
    "  plot_value_array(i, const_predictions[i], test_labels)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "print(\"\\033[1m\"+\"Distributed Model Results for Images \"+str(start_image)+\" to \"+str(end_image)+\"\\033[0m\")\n",
    "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
    "for i in range(start_image, end_image):\n",
    "  index = i % num_images\n",
    "  plt.subplot(num_rows, 2*num_cols, 2*index+1)\n",
    "  plot_image(i, distributed_predictions[i], test_labels, test_images)\n",
    "  plt.subplot(num_rows, 2*num_cols, 2*index+2)\n",
    "  plot_value_array(i, distributed_predictions[i], test_labels)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "print(\"\\033[1m\"+\"Adaptive Model Results for Images \"+str(start_image)+\" to \"+str(end_image)+\"\\033[0m\")\n",
    "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
    "for i in range(start_image, end_image):\n",
    "  index = i % num_images\n",
    "  plt.subplot(num_rows, 2*num_cols, 2*index+1)\n",
    "  plot_image(i, adaptive_predictions[i], test_labels, test_images)\n",
    "  plt.subplot(num_rows, 2*num_cols, 2*index+2)\n",
    "  plot_value_array(i, adaptive_predictions[i], test_labels)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8be0cc-a81a-43bc-a09d-3dee38028bbd",
   "metadata": {},
   "source": [
    "## Optional: See the bind mount for this JupyterLab environment\n",
    "The template that you use to run JupyterLab included a bind mount to the /tmp directory. This bind mount lets this Notebook access the validation images, as well as model checkpoints, saved to the shared file system. \n",
    "The cell below issues a det command (always preceded by ! in Notebooks) to show the config.\n",
    "Replace ID with the long string in the brower tab between \"proxy/\" and \"/lab.\" \n",
    "Then run the cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac07ec4e-11ce-4576-951f-49802be37ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!det notebook config id"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
